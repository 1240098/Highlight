import base64
import os
import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
import tempfile
import ffmpeg

import sidemenu as side


load_dotenv()  # ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

def __init__():
    st.session_state.shoq_hightlight_button=False
    st.session_state.show_submmit_form = False
    st.session_state.data = pd.DataFrame()

def init_page():
    st.set_page_config(page_title="ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºã‚¢ãƒ—ãƒª", page_icon="ğŸ¥", layout="centered", initial_sidebar_state="auto", menu_items=None)
    st.title("ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºã‚¢ãƒ—ãƒª")

def clear():
    st.session_state.shoq_hightlight_button=False
    st.session_state.show_submmit_form = False
    st.session_state.data = pd.DataFrame()

# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã®ç”Ÿæˆ
def create_download_link(file_path, download_name):
    with open(file_path, "rb") as f:
        bytes = f.read()
        b64 = base64.b64encode(bytes).decode()
        href = f'<a href="data:file/mp4;base64,{b64}" download="{download_name}">Download file</a>'
        return href


def cliping(start: float, end: float):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmpfile:
        tmpfile.write(st.session_state_audio.getvalue())

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as out_file:
        out_filename = out_file.name
    stream = ffmpeg.input(tmpfile.name, ss=start, t=end-start).output(out_filename)
    ffmpeg.run(stream, overwrite_output=True)

    # Streamlitã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º
    st.markdown(create_download_link(out_filename, "download.mp4"), unsafe_allow_html=True)
    
def main():
    init_page()
    type = side.selectType()
    side.selectExtractType()
    audio_file = st.file_uploader(
        "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["m4a", "mp3", "webm", "mp4", "mpga", "wav"]
    )
    st.session_state_audio=audio_file

    if audio_file is not None:
        # st.audio(audio_file, format="audio/wav")
        st.video(audio_file)
        
        # å‹•ç”»ã‹ã‚‰æ–‡å­—èµ·ã“ã—ã™ã‚‹
        # TODO ã§ã‹ã„ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯å¯¾å¿œã—ã¦ã„ãªã„ã®ã§ãƒãƒ£ãƒ³ã‚¯ï¼Ÿã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        if st.button("éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã™ã‚‹"):
            with st.spinner("éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œä¸­ã§ã™..."):
                transcript = client.audio.transcriptions.create(
                    model="whisper-1", file=audio_file, response_format="verbose_json"
                )
            st.success("éŸ³å£°æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            
            filtered_data = [
                {
                'start': str(item['start']),  # timedeltaã‚’ç§’æ•°ã®æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¾ã™ã€‚
                'end': str(item['end']),  # timedeltaã‚’ç§’æ•°ã®æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¾ã™ã€‚
                'content': item['text']
                }
                for item in transcript.segments
            ]
        
            st.session_state.whisper_data = filtered_data
            st.session_state.shoq_hightlight_button = True

        # æ–‡å­—èµ·ã“ã—ã•ã‚ŒãŸå­—å¹•ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆåˆ†æ
        if st.session_state.shoq_hightlight_button: 
            if st.button("ãƒã‚¤ãƒ©ã‚¤ãƒˆåˆ†æã‚’ã™ã‚‹"):
                with st.spinner("ãƒã‚¤ãƒ©ã‚¤ãƒˆåˆ†æä¸­ã§ã™..."):
                    initial_prompt = (
                        f"ã‚ãªãŸã¯ã‚¹ãƒãƒ¼ãƒ„ã®è¦³æˆ¦ä¸­ç¶™ã‹ã‚‰é‡è¦ãªã‚·ãƒ¼ãƒ³ã‚’å­—å¹•ã‹ã‚‰åˆ¤åˆ¥ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä»Šå›ã®å­—å¹•ãƒ‡ãƒ¼ã‚¿ã¯ã‚µãƒƒã‚«ãƒ¼ã®è©¦åˆã®å­—å¹•ã§ã™ã€‚ã‚ãªãŸãŒãƒã‚¤ãƒ©ã‚¤ãƒˆã ã¨æ€ã£ãŸã‚·ãƒ¼ãƒ³ã¯highlight!ã€ãã†ã§ãªã‹ã£ãŸã‚‰notã¨ç­”ãˆã¦ãã ã•ã„ã€‚å­—å¹•ã¯æ–­ç‰‡çš„ã«æµã‚Œã¦ãã¾ã™ã€‚éå»ã®çµæœã‚’å…ƒã«åˆ¤æ–­ã—ã¦ã‚‚è‰¯ã„ã§ã™ã€‚ãƒã‚¤ãƒ©ã‚¤ãƒˆã¨åˆ¤å®šã§ããªã‹ã£ãŸã‚‰ä¸€å¾‹ã§notã¨ç­”ãˆã¦å¤§ä¸ˆå¤«ã§ã™ã€‚' ")
                    messages = [{"role": "system", "content": initial_prompt}]
                    h = []
                    for message in st.session_state.whisper_data:
                        
                        messages.append({"role": "user", "content": message['content']})

                        res = client.chat.completions.create(
                            model="gpt-3.5-turbo", messages=messages
                        )

                        messages.append(
                            {"role": "assistant", "content": res.choices[0].message.content}
                        )

                        h.append({
                            'start' : message['start'],
                            'end' : message['end'],
                            'content' : message['content'],
                            'isHighlight' : res.choices[0].message.content  
                        })
                st.success("åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")  
                st.session_state.data = pd.DataFrame(h)
                st.session_state.show_submmit_form = True
       
        if not st.session_state.data.empty :
            st.dataframe(st.session_state.data)

        # æ™‚é–“æŒ‡å®šã—ã¦å‹•ç”»ã‚’ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰
        if type == 0 and st.session_state.show_submmit_form:
            with st.form("my_form", clear_on_submit=False):
                start = st.text_input('é–‹å§‹æ™‚é–“ã‚’æŒ‡å®šã—ã¦ãã ã•ã„')
                end = st.text_input('çµ‚äº†æ™‚é–“ã‚’æŒ‡å®šã—ã¦ãã ã•ã„')
                submitted = st.form_submit_button("å‹•ç”»ã®ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°")
            if submitted:
                with st.spinner("å‹•ç”»ã‚’ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã—ã¦ã„ã¾ã™..."):
                    cliping(float(start), float(end))
        
        # è‡ªå‹•çš„ã«ãƒã‚¤ãƒ©ã‚¤ãƒˆå‹•ç”»ã‚’ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰
        if type == 1 and st.session_state.show_submmit_form:
            if st.button("ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°"):
                counter = 0
                start = 0
                end = 0
                for is_highlight, start_time, end_time in zip(st.session_state.data['isHighlight'],st.session_state.data['start'],st.session_state.data['end']):
                    if(counter == 0 and is_highlight == 'highlight!'):
                        start = start_time
                        end = end_time
                        counter += 1
                    elif (counter > 0 and is_highlight == 'highlight!'):
                        end = end_time
                        counter += 1
                    elif (counter > 0 and is_highlight == 'not'):
                        cliping(float(start), float(end))
                        counter = 0
                        start = 0
                        end = 0
                
    else:
        clear()
        
if __name__ == '__main__':
    main()