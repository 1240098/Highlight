import base64
import os
from os.path import join, dirname
import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
import tempfile
import ffmpeg
import datetime
from pydub import AudioSegment
from pydub.silence import split_on_silence
import shutil
import tqdm

import sidemenu as side

# minutes
split_size = 10

load_dotenv(verbose=True)

dotenv_path = join(dirname(__file__), '.env')
load_dotenv(dotenv_path)

# ç’°å¢ƒå¤‰æ•°ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

def __init__():
    st.session_state.shoq_hightlight_button=False
    st.session_state.show_submmit_form = False
    st.session_state.data = pd.DataFrame()

def init_page():
    st.set_page_config(page_title="ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºã‚¢ãƒ—ãƒª", page_icon="ğŸ¥", layout="centered", initial_sidebar_state="auto", menu_items=None)
    st.title("ãƒã‚¤ãƒ©ã‚¤ãƒˆæ¤œå‡ºã‚¢ãƒ—ãƒª")

def clear():
    st.session_state.shoq_hightlight_button=False
    st.session_state.show_submmit_form = False
    st.session_state.data = pd.DataFrame()
    
# ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã®ç”Ÿæˆ
def create_download_link(file_path, download_name):
    with open(file_path, "rb") as f:
        bytes = f.read()
        b64 = base64.b64encode(bytes).decode()
        href = f'<a href="data:file/mp4;base64,{b64}" download="{download_name}">Download file</a>'
        return href


def cliping(start: float, end: float):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmpfile:
        tmpfile.write(st.session_state_audio.getvalue())

    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as out_file:
        out_filename = out_file.name
    stream = ffmpeg.input(tmpfile.name, ss=start, t=end-start).output(out_filename)
    ffmpeg.run(stream, overwrite_output=True)

    # Streamlitã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã‚’è¡¨ç¤º
    st.markdown(create_download_link(out_filename, "download.mp4"), unsafe_allow_html=True)

def split_audio_file(file_path, segment_length, temp_dir):
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã•ã‚ŒãŸé•·ã•ã§åˆ†å‰²ã™ã‚‹ã€‚

    :param file_path: åˆ†å‰²ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    :param segment_length: åˆ†å‰²ã™ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®é•·ã•ï¼ˆç§’ï¼‰
    :param temp_dir: ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
    :return: åˆ†å‰²ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
    """

    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
    audio = AudioSegment.from_file(file_path, format="mp4")

    # åˆ†å‰²ã™ã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®é•·ã•ã‚’ãƒŸãƒªç§’ã«å¤‰æ›
    segment_length_ms = segment_length * 1000

    # åˆ†å‰²ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’æ ¼ç´ã™ã‚‹ãƒªã‚¹ãƒˆ
    split_files = []

    for i in range(0, len(audio), segment_length_ms):
        # éŸ³å£°ã®ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’å–å¾—
        segment = audio[i:i + segment_length_ms]

        # åˆ†å‰²ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç”Ÿæˆ
        segment_file_path = f"{temp_dir}/segment_{i // segment_length_ms}.mp4"

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
        segment.export(segment_file_path, "mp4")

        # ãƒ‘ã‚¹ã‚’ãƒªã‚¹ãƒˆã«è¿½åŠ 
        split_files.append(segment_file_path)

    return split_files


def wisper_transcript(file):
    with open(file, 'rb') as audio_file:
        transcript = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file,
            response_format="verbose_json"
        )
    return transcript

def main():
    init_page()
    type = side.selectType()
    side.selectExtractType()
    audio_file = st.file_uploader(
        "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„", type=["m4a", "mp3", "webm", "mp4", "mpga", "wav"]
    )
    st.session_state_audio=audio_file
    
    if audio_file is not None:
        # st.audio(audio_file, format="audio/wav")
        st.video(audio_file)
        # å‹•ç”»ã‹ã‚‰æ–‡å­—èµ·ã“ã—ã™ã‚‹
        # TODO ã§ã‹ã„ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯å¯¾å¿œã—ã¦ã„ãªã„ã®ã§ãƒãƒ£ãƒ³ã‚¯ï¼Ÿã™ã‚‹å¿…è¦ãŒã‚ã‚‹
        if st.button("éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã™ã‚‹"):
            with st.spinner("éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œä¸­ã§ã™..."):
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãã®ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
                timestamp = datetime.datetime.now().strftime("%Y%m%d%H%M%S")
                temp_dir = f'./{timestamp}_temp'
                os.makedirs(temp_dir, exist_ok=True)
                st.session_state.temp_dir = temp_dir
                # åˆ†å‰²ã®å®Ÿè¡Œ
                split_files = split_audio_file(audio_file, split_size * 60, st.session_state.temp_dir)  # 10åˆ†åˆ»ã¿ã«åˆ†å‰²
                transcripts = [wisper_transcript(file) for file in split_files]
                # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤
                shutil.rmtree(st.session_state.temp_dir)
                
            st.success("éŸ³å£°æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            filtered_data = []
            for i ,transcript in enumerate(transcripts):
                filtered_data.extend([
                        {
                        'start': str(item['start']+(i * split_size * 60)),  # timedeltaã‚’ç§’æ•°ã®æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¾ã™ã€‚
                        'end': str(item['end']+(i * split_size * 60)),  # timedeltaã‚’ç§’æ•°ã®æ–‡å­—åˆ—ã«å¤‰æ›ã—ã¾ã™ã€‚
                        'content': item['text']
                        }
                        for item in transcript.segments
                ])
        
            st.session_state.whisper_data = filtered_data
            st.session_state.shoq_hightlight_button = True
            st.dataframe(pd.DataFrame(filtered_data))

        # æ–‡å­—èµ·ã“ã—ã•ã‚ŒãŸå­—å¹•ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆåˆ†æ
        if st.session_state.shoq_hightlight_button: 
            if st.button("ãƒã‚¤ãƒ©ã‚¤ãƒˆåˆ†æã‚’ã™ã‚‹"):
                with st.spinner("ãƒã‚¤ãƒ©ã‚¤ãƒˆåˆ†æä¸­ã§ã™..."):
                    initial_prompt = (
                        f"ã‚ãªãŸã¯ã‚¹ãƒãƒ¼ãƒ„ã®è¦³æˆ¦ä¸­ç¶™ã‹ã‚‰é‡è¦ãªã‚·ãƒ¼ãƒ³ã‚’å­—å¹•ã‹ã‚‰åˆ¤åˆ¥ã™ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚ä»Šå›ã®å­—å¹•ãƒ‡ãƒ¼ã‚¿ã¯ã‚µãƒƒã‚«ãƒ¼ã®è©¦åˆã®å­—å¹•ã§ã™ã€‚ã‚ãªãŸãŒãƒã‚¤ãƒ©ã‚¤ãƒˆã ã¨æ€ã£ãŸã‚·ãƒ¼ãƒ³ã¯highlight!ã€ãã†ã§ãªã‹ã£ãŸã‚‰notã¨ç­”ãˆã¦ãã ã•ã„ã€‚å­—å¹•ã¯æ–­ç‰‡çš„ã«æµã‚Œã¦ãã¾ã™ã€‚éå»ã®çµæœã‚’å…ƒã«åˆ¤æ–­ã—ã¦ã‚‚è‰¯ã„ã§ã™ã€‚ãƒã‚¤ãƒ©ã‚¤ãƒˆã¨åˆ¤å®šã§ããªã‹ã£ãŸã‚‰ä¸€å¾‹ã§notã¨ç­”ãˆã¦å¤§ä¸ˆå¤«ã§ã™ã€‚' ")
                    # messages = [{"role": "system", "content": initial_prompt}]
                    h = []
                    for message in tqdm.tqdm(st.session_state.whisper_data):
                        
                        # messages.append({"role": "user", "content": message['content']})

                        res = client.chat.completions.create(
                            model="gpt-3.5-turbo", messages=[
                                {"role": "system", "content": initial_prompt},
                                {"role": "user", "content": f"start:{message['start']}, end:{message['end']}, message:{message['content']}"}
                            ]
                        )

                        # messages.append(
                        #     {"role": "assistant", "content": res.choices[0].message.content}
                        # )

                        h.append({
                            'start' : message['start'],
                            'end' : message['end'],
                            'content' : message['content'],
                            'isHighlight' : res.choices[0].message.content  
                        })
                st.success("åˆ†æãŒå®Œäº†ã—ã¾ã—ãŸï¼")  
                st.session_state.data = pd.DataFrame(h)
                st.session_state.show_submmit_form = True
       
        if not st.session_state.data.empty :
            st.dataframe(st.session_state.data)

        # æ™‚é–“æŒ‡å®šã—ã¦å‹•ç”»ã‚’ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰
        if type == 0 and st.session_state.show_submmit_form:
            with st.form("my_form", clear_on_submit=False):
                start = st.text_input('é–‹å§‹æ™‚é–“ã‚’æŒ‡å®šã—ã¦ãã ã•ã„')
                end = st.text_input('çµ‚äº†æ™‚é–“ã‚’æŒ‡å®šã—ã¦ãã ã•ã„')
                submitted = st.form_submit_button("å‹•ç”»ã®ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°")
            if submitted:
                with st.spinner("å‹•ç”»ã‚’ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã—ã¦ã„ã¾ã™..."):
                    cliping(float(start), float(end))
        
        # è‡ªå‹•çš„ã«ãƒã‚¤ãƒ©ã‚¤ãƒˆå‹•ç”»ã‚’ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã™ã‚‹ãƒ¢ãƒ¼ãƒ‰
        if type == 1 and st.session_state.show_submmit_form:
            if st.button("ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°"):
                counter = 0
                start = 0
                end = 0
                for is_highlight, start_time, end_time in zip(st.session_state.data['isHighlight'],st.session_state.data['start'],st.session_state.data['end']):
                    if(counter == 0 and is_highlight == 'highlight!'):
                        start = start_time
                        end = end_time
                        counter += 1
                    elif (counter > 0 and is_highlight == 'highlight!'):
                        end = end_time
                        counter += 1
                    elif (counter > 0 and is_highlight == 'not'):
                        cliping(float(start), float(end))
                        counter = 0
                        start = 0
                        end = 0
                
    else:
        clear()
        
if __name__ == '__main__':
    main()